/* nedalloc, an alternative malloc implementation for multiple threads without
lock contention based on dlmalloc v2.8.4. (C) 2005-2010 Niall Douglas

Boost Software License - Version 1.0 - August 17th, 2003

Permission is hereby granted, free of charge, to any person or organization
obtaining a copy of the software and accompanying documentation covered by
this license (the "Software") to use, reproduce, display, distribute,
execute, and transmit the Software, and to prepare derivative works of the
Software, and to permit third-parties to whom the Software is furnished to
do so, all subject to the following:

The copyright notices in the Software and this entire statement, including
the above license grant, this restriction and the following disclaimer,
must be included in all copies of the Software, in whole or in part, and
all derivative works of the Software, unless such copies or derivative
works are solely in the form of machine-executable object code generated by
a source language processor.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
DEALINGS IN THE SOFTWARE.
*/

#ifndef NEDMALLOC_H
#define NEDMALLOC_H

/*! \file nedmalloc.h

Defines the functionality provided by nedalloc.
*/

/*! \mainpage

<a href="../../Readme.html">Please see the Readme.html</a>
*/

/*! \def USE_LOCKS
USE_LOCKS can be 2 if you want to define your own MLOCK_T, INITIAL_LOCK,
ACQUIRE_LOCK, RELEASE_LOCK, TRY_LOCK, IS_LOCKED and NULL_LOCK_INITIALIZER.
*/

/*! \def NEDMALLOC_DEBUG
NEDMALLOC_DEBUG can be defined to cause DEBUG to be set differently for nedmalloc
than for the rest of the build. Remember to set NDEBUG to disable all assertion
checking too.
*/

/*! \def ENABLE_LARGE_PAGES
ENABLE_LARGE_PAGES enables support for requesting memory from the system in large
(typically >=2Mb) pages if the host OS supports this. These occupy just a single
TLB entry and can significantly improve performance in large working set applications.
*/

/* \def ENABLE_FAST_HEAP_DETECTION
ENABLE_FAST_HEAP_DETECTION enables special logic to detect blocks allocated
by the system heap. This avoids 1.5%-2% overhead when checking for non-nedmalloc
blocks, but it assumes that the NT and glibc heaps function in a very specific
fashion which may not hold true across OS upgrades.
*/

#include <stddef.h>   /* for size_t */

/*! \def NEDMALLOCEXTSPEC
NEDMALLOCEXTSPEC can be defined to be __declspec(dllexport) or
__attribute__ ((visibility("default"))) or whatever you like. It defaults
to extern unless NEDMALLOC_DLL_EXPORTS is set as it would be when building
nedmalloc.dll.
 */
#ifndef NEDMALLOCEXTSPEC
 #ifdef NEDMALLOC_DLL_EXPORTS
  #ifdef WIN32
   #define NEDMALLOCEXTSPEC extern __declspec(dllexport)
  #elif defined(__GNUC__)
   #define NEDMALLOCEXTSPEC extern __attribute__ ((visibility("default")))
  #endif
  #ifndef ENABLE_TOLERANT_NEDMALLOC
   #define ENABLE_TOLERANT_NEDMALLOC 1
  #endif
 #else
  #define NEDMALLOCEXTSPEC extern
 #endif
#endif

/*! \def RESTRICT
Defined to the restrict keyword or equivalent if available */
#ifndef RESTRICT
#if __STDC_VERSION__ >= 199901L		/* C99 or better */
 #define RESTRICT restrict
#else
 #if defined(_MSC_VER) && _MSC_VER>=1400
  #define RESTRICT __restrict
 #endif
 #ifdef __GNUC__
  #define RESTRICT __restrict
 #endif
#endif
#ifndef RESTRICT
 #define RESTRICT
#endif
#endif

#if defined(_MSC_VER) && _MSC_VER>=1400
 #define NEDMALLOCPTRATTR __declspec(restrict)
 #define NEDMALLOCNOALIASATTR __declspec(noalias)
#endif
#ifdef __GNUC__
 #define NEDMALLOCPTRATTR __attribute__ ((malloc))
#endif
/*! \def NEDMALLOCPTRATTR
Defined to the specifier for a pointer which points to a memory block. Like NEDMALLOCNOALIASATTR, but sadly not identical. */
#ifndef NEDMALLOCPTRATTR
 #define NEDMALLOCPTRATTR
#endif
/*! \def NEDMALLOCNOALIASATTR
Defined to the specifier for a pointer which does not alias any other variable. */
#ifndef NEDMALLOCNOALIASATTR
 #define NEDMALLOCNOALIASATTR
#endif

/*! \def USE_MAGIC_HEADERS
USE_MAGIC_HEADERS causes nedalloc to allocate an extra three sizeof(size_t)
to each block. nedpfree() and nedprealloc() can then automagically know when
to free a system allocated block. Enabling this typically adds 20-50% to
application memory usage, and is mandatory if USE_ALLOCATOR is not 1.
*/
#ifndef USE_MAGIC_HEADERS
 #define USE_MAGIC_HEADERS 0
#endif

/*! \def USE_ALLOCATOR
USE_ALLOCATOR can be one of these settings (it defaults to 1):
  0: System allocator (nedmalloc now simply acts as a threadcache) which is
     very useful for testing with valgrind and Glowcode.
     WARNING: Intended for DEBUG USE ONLY - not all functions work correctly.
  1: dlmalloc
*/
#ifndef USE_ALLOCATOR
 #define USE_ALLOCATOR 1 /* dlmalloc */
#endif

#if !USE_ALLOCATOR && !USE_MAGIC_HEADERS
#error If you are using the system allocator then you MUST use magic headers
#endif

/*! \def REPLACE_SYSTEM_ALLOCATOR
REPLACE_SYSTEM_ALLOCATOR on POSIX causes nedalloc's functions to be called
malloc, free etc. instead of nedmalloc, nedfree etc. You may or may not want
this. On Windows it causes nedmalloc to patch all loaded DLLs and binaries
to replace usage of the system allocator.

Always turns on ENABLE_TOLERANT_NEDMALLOC.
*/
#ifdef REPLACE_SYSTEM_ALLOCATOR
 #if USE_ALLOCATOR==0
  #error Cannot combine using the system allocator with replacing the system allocator
 #endif
 #ifndef ENABLE_TOLERANT_NEDMALLOC
  #define ENABLE_TOLERANT_NEDMALLOC 1
 #endif
 #ifndef WIN32	/* We have a dedicated patcher for Windows */
  #define nedmalloc               malloc
  #define nedcalloc               calloc
  #define nedrealloc              realloc
  #define nedfree                 free
  #define nedmemalign             memalign
  #define nedmallinfo             mallinfo
  #define nedmallopt              mallopt
  #define nedmalloc_trim          malloc_trim
  #define nedmalloc_stats         malloc_stats
  #define nedmalloc_footprint     malloc_footprint
  #define nedindependent_calloc   independent_calloc
  #define nedindependent_comalloc independent_comalloc
  #ifdef _MSC_VER
   #define nedblksize              _msize
  #endif
 #endif
#endif

/*! \def ENABLE_TOLERANT_NEDMALLOC
ENABLE_TOLERANT_NEDMALLOC is automatically turned on if REPLACE_SYSTEM_ALLOCATOR
is set or the Windows DLL is being built. This causes nedmalloc to detect when a
system allocator block is passed to it and to handle it appropriately. Note that
without USE_MAGIC_HEADERS there is a very tiny chance that nedmalloc will segfault
on non-Windows builds (it uses Win32 SEH to trap segfaults on Windows and there
is no comparable system on POSIX).
*/

#if defined(__cplusplus)
extern "C" {
#endif
/*! Returns information about a memory pool */
struct nedmallinfo {
  size_t arena;    /*!< non-mmapped space allocated from system */
  size_t ordblks;  /*!< number of free chunks */
  size_t smblks;   /*!< always 0 */
  size_t hblks;    /*!< always 0 */
  size_t hblkhd;   /*!< space in mmapped regions */
  size_t usmblks;  /*!< maximum total allocated space */
  size_t fsmblks;  /*!< always 0 */
  size_t uordblks; /*!< total allocated space */
  size_t fordblks; /*!< total free space */
  size_t keepcost; /*!< releasable (via malloc_trim) space */
};
#if defined(__cplusplus)
}
#endif

/*! \def NO_NED_NAMESPACE
NO_NED_NAMESPACE prevents the functions from being defined in the nedalloc
namespace when in C++ (uses the global C namespace instead).
*/
/*! \def THROWSPEC
Defined to throw() or noexcept(true) (as in, throws nothing) under C++, otherwise nothing.
*/
#if defined(__cplusplus)
 #if !defined(NO_NED_NAMESPACE)
namespace nedalloc {
 #else
extern "C" {
 #endif
 #if __cplusplus > 199711L
  #define THROWSPEC noexcept(true)
 #else
  #define THROWSPEC throw()
 #endif
#else
 #define THROWSPEC
#endif

/* These are the global functions */

/*! Gets the usable size of an allocated block. Note this will always be bigger than what was
asked for due to rounding etc. Optionally returns 1 in isforeign if the block came from the
system allocator - note that there is a small (>0.01%) but real chance of segfault on non-Windows
systems when passing non-nedmalloc blocks if you don't use USE_MAGIC_HEADERS.
*/
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR size_t nedblksize(int *RESTRICT isforeign, void *RESTRICT mem) THROWSPEC;
/*! Identical to nedblksize() except without the isforeign */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR size_t nedmemsize(void *RESTRICT mem) THROWSPEC;

/*! Equivalent to nedpsetvalue((nedpool *) 0, v) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR void nedsetvalue(void *v) THROWSPEC;

/*! Equivalent to nedpmalloc2((nedpool *) 0, size, 0, 0) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedmalloc(size_t size) THROWSPEC;
/*! Equivalent to nedpmalloc2((nedpool *) 0, no*size, 0, M2_ZERO_MEMORY) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedcalloc(size_t no, size_t size) THROWSPEC;
/*! Equivalent to nedprealloc2((nedpool *) 0, size, mem, size, 0, 0) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedrealloc(void *mem, size_t size) THROWSPEC;
/*! Equivalent to nedpfree((nedpool *) 0, mem) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR void   nedfree(void *mem) THROWSPEC;
/*! Equivalent to nedpmalloc2((nedpool *) 0, size, alignment, 0) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedmemalign(size_t alignment, size_t bytes) THROWSPEC;

#if defined(__cplusplus)
/*! Equivalent to nedpmalloc2((nedpool *) 0, size, alignment, flags) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedmalloc2(size_t size, size_t alignment=0, unsigned flags=0) THROWSPEC;
/*! Equivalent to nedprealloc2((nedpool *) 0, mem, size, alignment, flags) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedrealloc2(void *mem, size_t size, size_t alignment=0, unsigned flags=0) THROWSPEC;
#else
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedmalloc2(size_t size, size_t alignment, unsigned flags) THROWSPEC;
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedrealloc2(void *mem, size_t size, size_t alignment, unsigned flags) THROWSPEC;
#endif

/*! Equivalent to nedpmallinfo((nedpool *) 0) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR struct nedmallinfo nedmallinfo(void) THROWSPEC;
/*! Equivalent to nedpmallopt((nedpool *) 0, parno, value) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR int    nedmallopt(int parno, int value) THROWSPEC;
/*! Returns the internal allocation granularity and the magic header XOR used for internal consistency checks. */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR void*  nedmalloc_internals(size_t *granularity, size_t *magic) THROWSPEC;
/*! Equivalent to nedpmalloc_trim((nedpool *) 0, pad) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR int    nedmalloc_trim(size_t pad) THROWSPEC;
/*! Equivalent to nedpmalloc_stats((nedpool *) 0) */
NEDMALLOCEXTSPEC void   nedmalloc_stats(void) THROWSPEC;
/*! Equivalent to nedpmalloc_footprint((nedpool *) 0) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR size_t nedmalloc_footprint(void) THROWSPEC;
/*! Equivalent to nedpindependent_calloc((nedpool *) 0, elemsno, elemsize, chunks) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void **nedindependent_calloc(size_t elemsno, size_t elemsize, void **chunks) THROWSPEC;
/*! Equivalent to nedpindependent_comalloc((nedpool *) 0, elems, sizes, chunks) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void **nedindependent_comalloc(size_t elems, size_t *sizes, void **chunks) THROWSPEC;

/*! Destroys the system memory pool used by the functions above.
Useful for when you have nedmalloc in a DLL you're about to unload.
If you call ANY nedmalloc functions after calling this you will
get a fatal exception!
*/
NEDMALLOCEXTSPEC void neddestroysyspool() THROWSPEC;

/*! A nedpool type */
struct nedpool_t;
/*! A nedpool type */
typedef struct nedpool_t nedpool;

/*! Creates a memory pool for use with the nedp* functions below.
Capacity is how much to allocate immediately (if you know you'll be allocating a lot
of memory very soon) which you can leave at zero. Threads specifies how many threads
will *normally* be accessing the pool concurrently. Setting this to zero means it
extends on demand, but be careful of this as it can rapidly consume system resources
where bursts of concurrent threads use a pool at once.
*/
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR nedpool *nedcreatepool(size_t capacity, int threads) THROWSPEC;

/*! Destroys a memory pool previously created by nedcreatepool().
*/
NEDMALLOCEXTSPEC void neddestroypool(nedpool *p) THROWSPEC;

/*! Returns a zero terminated snapshot of threadpools existing at the time of call. Call
nedfree() on the returned list when you are done. Returns zero if there is only the
system pool in existence.
*/
NEDMALLOCEXTSPEC nedpool **nedpoollist() THROWSPEC;

/*! Sets a value to be associated with a pool. You can retrieve this value by passing
any memory block allocated from that pool.
*/
NEDMALLOCEXTSPEC void nedpsetvalue(nedpool *p, void *v) THROWSPEC;

/*! Gets a previously set value using nedpsetvalue() or zero if memory is unknown.
Optionally can also retrieve pool. You can detect an unknown block by the return
being zero and *p being unmodifed.
*/
NEDMALLOCEXTSPEC void *nedgetvalue(nedpool **p, void *mem) THROWSPEC;

/*! Trims the thread cache for the calling thread, returning any existing cache
data to the central pool. Remember to ALWAYS call with zero if you used the
system pool. Setting disable to non-zero replicates neddisablethreadcache().
*/
NEDMALLOCEXTSPEC void nedtrimthreadcache(nedpool *p, int disable) THROWSPEC;

/*! Disables the thread cache for the calling thread, returning any existing cache
data to the central pool. Remember to ALWAYS call with zero if you used the
system pool.
*/
NEDMALLOCEXTSPEC void neddisablethreadcache(nedpool *p) THROWSPEC;

/*! Equivalent to nedpmalloc2(p, size, 0, 0) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedpmalloc(nedpool *p, size_t size) THROWSPEC;
/*! Equivalent to nedpmalloc2(p, no*size, 0, M2_ZERO_MEMORY) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedpcalloc(nedpool *p, size_t no, size_t size) THROWSPEC;
/*! Equivalent to nedprealloc2(p, mem, size, 0, 0) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedprealloc(nedpool *p, void *mem, size_t size) THROWSPEC;
/*! Frees the block mem from the pool p. */
NEDMALLOCEXTSPEC void   nedpfree(nedpool *p, void *mem) THROWSPEC;
/*! Equivalent to nedpmalloc2(p, bytes, alignment, 0) */
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedpmemalign(nedpool *p, size_t alignment, size_t bytes) THROWSPEC;
#if defined(__cplusplus)
/*! \ingroup v2malloc
Allocates a block of memory sized \em size from pool \em p, aligned to \em alignment and according to the flags \em flags.
*/
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedpmalloc2(nedpool *p, size_t size, size_t alignment=0, unsigned flags=0) THROWSPEC;
/*! \ingroup v2malloc
Resizes the block of memory at \em mem in pool \em p to size \em size, aligned to \em alignment and according to the flags \em flags.
*/
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedprealloc2(nedpool *p, void *mem, size_t size, size_t alignment=0, unsigned flags=0) THROWSPEC;
#else
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedpmalloc2(nedpool *p, size_t size, size_t alignment, unsigned flags) THROWSPEC;
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void * nedprealloc2(nedpool *p, void *mem, size_t size, size_t alignment, unsigned flags) THROWSPEC;
#endif
/*! Returns information about the memory pool */
NEDMALLOCEXTSPEC struct nedmallinfo nedpmallinfo(nedpool *p) THROWSPEC;
/*! Changes the operational parameters of the memory pool */
NEDMALLOCEXTSPEC int    nedpmallopt(nedpool *p, int parno, int value) THROWSPEC;
/*! Tries to release as much free memory back to the system as possible, leaving \em pad remaining per threadpool. */
NEDMALLOCEXTSPEC int    nedpmalloc_trim(nedpool *p, size_t pad) THROWSPEC;
/*! Prints some operational statistics to stdout. */
NEDMALLOCEXTSPEC void   nedpmalloc_stats(nedpool *p) THROWSPEC;
/*! Returns how much memory is currently in use by the memory pool */
NEDMALLOCEXTSPEC size_t nedpmalloc_footprint(nedpool *p) THROWSPEC;
/*! independent_calloc is similar to calloc, but instead of returning a
  single cleared space, it returns an array of pointers to n_elements
  independent elements that can hold contents of size elem_size, each
  of which starts out cleared, and can be independently freed,
  realloc'ed etc. The elements are guaranteed to be adjacently
  allocated (this is not guaranteed to occur with multiple callocs or
  mallocs), which may also improve cache locality in some
  applications.

  The "chunks" argument is optional (i.e., may be null, which is
  probably the most typical usage). If it is null, the returned array
  is itself dynamically allocated and should also be freed when it is
  no longer needed. Otherwise, the chunks array must be of at least
  n_elements in length. It is filled in with the pointers to the
  chunks.

  In either case, independent_calloc returns this pointer array, or
  null if the allocation failed.  If n_elements is zero and "chunks"
  is null, it returns a chunk representing an array with zero elements
  (which should be freed if not wanted).

  Each element must be individually freed when it is no longer
  needed. If you'd like to instead be able to free all at once, you
  should instead use regular calloc and assign pointers into this
  space to represent elements.  (In this case though, you cannot
  independently free elements.)

  independent_calloc simplifies and speeds up implementations of many
  kinds of pools.  It may also be useful when constructing large data
  structures that initially have a fixed number of fixed-sized nodes,
  but the number is not known at compile time, and some of the nodes
  may later need to be freed. For example:

  struct Node { int item; struct Node* next; };

  struct Node* build_list() {
    struct Node** pool;
    int n = read_number_of_nodes_needed();
    if (n <= 0) return 0;
    pool = (struct Node**)(independent_calloc(n, sizeof(struct Node), 0);
    if (pool == 0) die();
    // organize into a linked list...
    struct Node* first = pool[0];
    for (i = 0; i < n-1; ++i)
      pool[i]->next = pool[i+1];
    free(pool);     // Can now free the array (or not, if it is needed later)
    return first;
  }
*/
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void **nedpindependent_calloc(nedpool *p, size_t elemsno, size_t elemsize, void **chunks) THROWSPEC;
/*!   independent_comalloc allocates, all at once, a set of n_elements
  chunks with sizes indicated in the "sizes" array.    It returns
  an array of pointers to these elements, each of which can be
  independently freed, realloc'ed etc. The elements are guaranteed to
  be adjacently allocated (this is not guaranteed to occur with
  multiple callocs or mallocs), which may also improve cache locality
  in some applications.

  The "chunks" argument is optional (i.e., may be null). If it is null
  the returned array is itself dynamically allocated and should also
  be freed when it is no longer needed. Otherwise, the chunks array
  must be of at least n_elements in length. It is filled in with the
  pointers to the chunks.

  In either case, independent_comalloc returns this pointer array, or
  null if the allocation failed.  If n_elements is zero and chunks is
  null, it returns a chunk representing an array with zero elements
  (which should be freed if not wanted).

  Each element must be individually freed when it is no longer
  needed. If you'd like to instead be able to free all at once, you
  should instead use a single regular malloc, and assign pointers at
  particular offsets in the aggregate space. (In this case though, you
  cannot independently free elements.)

  independent_comallac differs from independent_calloc in that each
  element may have a different size, and also that it does not
  automatically clear elements.

  independent_comalloc can be used to speed up allocation in cases
  where several structs or objects must always be allocated at the
  same time.  For example:

  struct Head { ... }
  struct Foot { ... }

  void send_message(char* msg) {
    int msglen = strlen(msg);
    size_t sizes[3] = { sizeof(struct Head), msglen, sizeof(struct Foot) };
    void* chunks[3];
    if (independent_comalloc(3, sizes, chunks) == 0)
      die();
    struct Head* head = (struct Head*)(chunks[0]);
    char*        body = (char*)(chunks[1]);
    struct Foot* foot = (struct Foot*)(chunks[2]);
    // ...
  }

  In general though, independent_comalloc is worth using only for
  larger values of n_elements. For small values, you probably won't
  detect enough difference from series of malloc calls to bother.

  Overuse of independent_comalloc can increase overall memory usage,
  since it cannot reuse existing noncontiguous small chunks that
  might be available for some of the elements.
*/
NEDMALLOCEXTSPEC NEDMALLOCNOALIASATTR NEDMALLOCPTRATTR void **nedpindependent_comalloc(nedpool *p, size_t elems, size_t *sizes, void **chunks) THROWSPEC;

#if defined(__cplusplus)
} /* namespace or extern "C" */
#include <new>
#include <memory>
/*! The nedalloc namespace */
namespace nedalloc {

namespace nedallocatorI
{
	/* Roll on variadic templates is all I can say! */
#if __cplusplus > 199711L
	template<class... policies> class policycompositor
		: public policies...
	{
	};
#else
	template<int n> struct nullpolicy
	{
		template<typename T> class policy {};
	};
	template<int n> class NullType {};
	template<class A=NullType<1>, class B=NullType<2>, class C=NullType<3>, class D=NullType<4>, class E=NullType<5>,
		class F=NullType<6>, class G=NullType<7>, class H=NullType<8>, class I=NullType<9>, class J=NullType<10>,
		class K=NullType<11>, class L=NullType<12>, class M=NullType<13>, class N=NullType<14>, class O=NullType<15> > class policycompositor
		: public A, public B, public C, public D, public E,
		public F, public G, public H, public I, public J,
		public K, public L, public M, public N, public O
	{
	};
#endif
}

template<typename T,
#if __cplusplus > 199711L
	class... policies
#else
	class policy1=nedallocatorI::nullpolicy<1>,
	class policy2=nedallocatorI::nullpolicy<2>,
	class policy3=nedallocatorI::nullpolicy<3>,
	class policy4=nedallocatorI::nullpolicy<4>,
	class policy5=nedallocatorI::nullpolicy<5>
#endif
> class nedallocator;

namespace nedallocatorI
{
	template<class implementation> class baseimplementation;
	template<typename T,
#if __cplusplus > 199711L
			class... policies
#else
			class policy1,
			class policy2,
			class policy3,
			class policy4,
			class policy5
#endif
	> class baseimplementation<nedallocator<T,
#if __cplusplus > 199711L
	policies...
#else
	policy1, policy2, policy3, policy4, policy5
#endif
	> >
	{
	protected:
		//! The most derived nedallocator implementation type
		typedef nedallocator<T,
#if __cplusplus > 199711L
			policies...
#else
			policy1, policy2, policy3, policy4, policy5
#endif
		> implementationType;
		//! Returns a this for the most derived nedallocator implementation type
		implementationType *_this() { return static_cast<implementationType *>(this); }
		//! Returns a this for the most derived nedallocator implementation type
		const implementationType *_this() const { return static_cast<const implementationType *>(this); }
		//! Specifies the nedpool to use. Defaults to zero (the system pool).
		nedpool *policy_nedpool(size_t bytes) const
		{
			return 0;
		}
		//! Specifies the granularity to use. Defaults to \em bytes (no granularity).
		size_t policy_granularity(size_t bytes) const
		{
			return bytes;
		}
		//! Specifies the alignment to use. Defaults to zero (no alignment).
		size_t policy_alignment(size_t bytes) const
		{
			return 0;
		}
		//! Specifies the flags to use. Defaults to zero (no flags).
		unsigned policy_flags(size_t bytes) const
		{
			return 0;
		}
		//! Specifies what to do when the allocation fails. Defaults to throwing std::bad_alloc.
		void policy_throwbadalloc(size_t bytes) const
		{
			throw std::bad_alloc("Out of memory");
		}
	public:
		typedef T *pointer;
		typedef const T *const_pointer;
		typedef T &reference;
		typedef const T &const_reference;
		typedef T value_type;
		typedef size_t size_type;
		typedef ptrdiff_t difference_type;
		T *address(T &r) const { return &r; }
		const T *address(const T &s) const { return &s; }
		size_t max_size() const { return (static_cast<size_t>(0) - static_cast<size_t>(1)) / sizeof(T); }
		bool operator!=(const baseimplementation &other) const { return !(*this == other); }
		bool operator==(const baseimplementation &other) const { return true; }

		void construct(T *const p, const T &t) const {
			void *const _p = static_cast<void *>(p);
			new (_p) T(t);
		}
		void destroy(T *const p) const {
			p->~T();
		}
		baseimplementation() { }
		baseimplementation(const baseimplementation &) { }
		template<typename U> struct rebind {
			typedef nedallocator<U,
#if __cplusplus > 199711L
				policies...
#else
				policy1, policy2, policy3, policy4, policy5
#endif
			> other;
		};
		template<typename U> baseimplementation(const nedallocator<U,
#if __cplusplus > 199711L
			policies...
#else
			policy1, policy2, policy3, policy4, policy5
#endif
		> &) { }
#if __cplusplus > 199711L
		baseimplementation(baseimplementation &&) { }
#endif

		T *allocate(const size_t n) const {
			size_t size = _this()->policy_granularity(n*sizeof(T));
			void *ptr = nedpmalloc2(_this()->policy_nedpool(size), size, _this()->policy_alignment(size), _this()->policy_flags(size));
			if(!ptr) _this()->policy_throwbadalloc(size);
			return static_cast<T *>(ptr);
		}
		void deallocate(T *p, const size_t n) const {
			nedpfree(0/*not needed*/, p);
		}
		template<typename U> T *allocate(const size_t n, const U * /* hint */) const {
			return allocate(n);
		}
	private:
		baseimplementation &operator=(const baseimplementation &);
	};
}
/*! \class nedalignment
\ingroup C++
\brief An alignment policy setting the alignment of the allocated memory.
*/
template<size_t alignment> struct nedalignment
{
	template<class implementation> class policy
	{
	protected:
		size_t policy_alignment(size_t bytes) const
		{
			return alignment;
		}
	};
};

/*! \class nedallocator
\ingroup C++
\brief A policy driven STL allocator which uses nedmalloc

One of the lesser known features of STL container classes is their ability to take
an allocator implementation class, so where you had std::vector<Foo> you can now
have std::vector<Foo, nedalloc::nedallocator< std::vector<Foo> > such that
std::vector<> will now use nedalloc as the policy specifies.
*/
template<typename T,
#if __cplusplus > 199711L
	class... policies
#else
	class policy1,
	class policy2,
	class policy3,
	class policy4,
	class policy5
#endif
> class nedallocator : public nedallocatorI::policycompositor<
#if __cplusplus > 199711L
	nedallocatorI::baseimplementation<nedallocator<T, policies...> >,
	typename policies::policy<nedallocator<T, policies...> >...
#else
	nedallocatorI::baseimplementation<nedallocator<T, policy1, policy2, policy3, policy4, policy5> >,
	typename policy1::policy<nedallocator<T, policy1, policy2, policy3, policy4, policy5> >,
	typename policy2::policy<nedallocator<T, policy1, policy2, policy3, policy4, policy5> >,
	typename policy3::policy<nedallocator<T, policy1, policy2, policy3, policy4, policy5> >,
	typename policy4::policy<nedallocator<T, policy1, policy2, policy3, policy4, policy5> >,
	typename policy5::policy<nedallocator<T, policy1, policy2, policy3, policy4, policy5> >
#endif
>
{
	typedef nedallocatorI::policycompositor<
#if __cplusplus > 199711L
		nedallocatorI::baseimplementation<nedallocator<T, policies...> >,
		typename policies::policy<nedallocator<T, policies...> >...
#else
		nedallocatorI::baseimplementation<nedallocator<T, policy1, policy2, policy3, policy4, policy5> >,
		typename policy1::policy<nedallocator<T, policy1, policy2, policy3, policy4, policy5> >,
		typename policy2::policy<nedallocator<T, policy1, policy2, policy3, policy4, policy5> >,
		typename policy3::policy<nedallocator<T, policy1, policy2, policy3, policy4, policy5> >,
		typename policy4::policy<nedallocator<T, policy1, policy2, policy3, policy4, policy5> >,
		typename policy5::policy<nedallocator<T, policy1, policy2, policy3, policy4, policy5> >
#endif
	> Base;
public:
};


} /* namespace */
#endif

#endif
